# features/example_audio/ Module

## Purpose

Handles playback of pre-generated example audio (male/female voices) for text sequences. Audio is generated by the Python tool and either bundled or downloaded.

## Folder Structure

```
example_audio/
├── domain/
│   └── example_audio_repository.dart   # Resolves audio sources
└── data/
    └── example_audio_repository_impl.dart  # Asset/cache impl
└── presentation/
    └── example_audio_controller.dart   # Playback state
```

---

## Domain Layer

### `example_audio_repository.dart`

**Purpose**: Resolves example audio URIs to playable sources.

**Implementation**:

```dart
import '../../core/audio/audio_player.dart';
import '../text_sequences/domain/text_sequence.dart';

/// Repository for resolving and accessing example audio.
abstract class ExampleAudioRepository {
  /// Resolves an example audio URI to a playable source.
  ///
  /// URIs can be:
  /// - `assets://path/to/file.opus` - bundled asset
  /// - `https://cdn.example.com/file.opus` - remote (cached)
  /// - `file:///path/to/file.opus` - local file
  ///
  /// Returns null if the audio is not available and cannot be fetched.
  Future<AudioSource?> resolve(String uri);

  /// Resolves example audio for a specific voice.
  ///
  /// Convenience method that finds the voice and resolves its URI.
  Future<AudioSource?> resolveVoice(TextSequence sequence, String voiceId);

  /// Pre-fetches audio for a sequence (downloads if remote).
  Future<void> prefetch(TextSequence sequence);

  /// Checks if audio is available locally (cached or bundled).
  Future<bool> isAvailableLocally(String uri);
}
```

---

## Data Layer

### `example_audio_repository_impl.dart`

**Purpose**: Implementation handling assets and cached downloads.

**Implementation**:

```dart
import 'dart:io';
import 'package:dio/dio.dart';
import 'package:path_provider/path_provider.dart';
import 'package:crypto/crypto.dart';
import 'dart:convert';
import '../../core/audio/audio_player.dart';
import '../text_sequences/domain/text_sequence.dart';
import '../domain/example_audio_repository.dart';

class ExampleAudioRepositoryImpl implements ExampleAudioRepository {
  final Dio _dio;

  /// LRU cache limit (number of files).
  static const _maxCacheFiles = 200;

  ExampleAudioRepositoryImpl({Dio? dio}) : _dio = dio ?? Dio();

  Future<String> get _cacheDir async {
    final appDir = await getApplicationSupportDirectory();
    final dir = Directory('${appDir.path}/audio_cache');
    if (!await dir.exists()) {
      await dir.create(recursive: true);
    }
    return dir.path;
  }

  @override
  Future<AudioSource?> resolve(String uri) async {
    final parsed = Uri.parse(uri);

    return switch (parsed.scheme) {
      'assets' => _resolveAsset(uri),
      'file' => _resolveFile(parsed.path),
      'https' || 'http' => _resolveRemote(uri),
      _ => null,
    };
  }

  @override
  Future<AudioSource?> resolveVoice(TextSequence sequence, String voiceId) async {
    final voice = sequence.exampleAudio.firstWhere(
      (v) => v.id == voiceId,
      orElse: () => throw ArgumentError('Voice not found: $voiceId'),
    );
    return resolve(voice.uri);
  }

  @override
  Future<void> prefetch(TextSequence sequence) async {
    for (final voice in sequence.exampleAudio) {
      final uri = Uri.parse(voice.uri);
      if (uri.scheme == 'https' || uri.scheme == 'http') {
        await _downloadToCache(voice.uri);
      }
    }
  }

  @override
  Future<bool> isAvailableLocally(String uri) async {
    final parsed = Uri.parse(uri);

    return switch (parsed.scheme) {
      'assets' => true, // Bundled assets always available
      'file' => File(parsed.path).exists(),
      'https' || 'http' => _isCached(uri),
      _ => false,
    };
  }

  AudioSource _resolveAsset(String uri) {
    // Convert assets://path/to/file to assets/path/to/file
    final path = uri.replaceFirst('assets://', 'assets/');
    return AssetAudioSource(path);
  }

  AudioSource? _resolveFile(String path) {
    final file = File(path);
    if (file.existsSync()) {
      return FileAudioSource(path);
    }
    return null;
  }

  Future<AudioSource?> _resolveRemote(String url) async {
    // Check cache first
    final cachedPath = await _getCachedPath(url);
    if (await File(cachedPath).exists()) {
      return FileAudioSource(cachedPath);
    }

    // Download to cache
    final downloaded = await _downloadToCache(url);
    if (downloaded != null) {
      return FileAudioSource(downloaded);
    }

    // Fallback to streaming (may not work for all players)
    return UrlAudioSource(url);
  }

  Future<bool> _isCached(String url) async {
    final path = await _getCachedPath(url);
    return File(path).exists();
  }

  Future<String> _getCachedPath(String url) async {
    final dir = await _cacheDir;
    final hash = md5.convert(utf8.encode(url)).toString();
    final extension = url.split('.').last.split('?').first;
    return '$dir/$hash.$extension';
  }

  Future<String?> _downloadToCache(String url) async {
    try {
      final path = await _getCachedPath(url);
      await _dio.download(url, path);
      await _cleanupCache();
      return path;
    } catch (e) {
      return null;
    }
  }

  Future<void> _cleanupCache() async {
    final dir = Directory(await _cacheDir);
    if (!await dir.exists()) return;

    final files = await dir.list().toList();
    if (files.length <= _maxCacheFiles) return;

    // Sort by last accessed time, delete oldest
    final fileStats = <File, FileStat>{};
    for (final entity in files) {
      if (entity is File) {
        fileStats[entity] = await entity.stat();
      }
    }

    final sorted = fileStats.entries.toList()
      ..sort((a, b) => a.value.accessed.compareTo(b.value.accessed));

    final toDelete = sorted.take(files.length - _maxCacheFiles);
    for (final entry in toDelete) {
      await entry.key.delete();
    }
  }
}
```

---

## Presentation Layer

### `example_audio_controller.dart`

**Purpose**: State management for example audio playback.

**Implementation**:

```dart
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:freezed_annotation/freezed_annotation.dart';
import '../../core/audio/audio_player.dart';
import '../domain/example_audio_repository.dart';
import '../text_sequences/domain/text_sequence_repository.dart';

part 'example_audio_controller.freezed.dart';

@freezed
class ExampleAudioState with _$ExampleAudioState {
  const factory ExampleAudioState({
    @Default(false) bool isPlaying,
    String? currentSequenceId,
    String? currentVoiceId,
    String? error,
  }) = _ExampleAudioState;
}

final exampleAudioControllerProvider =
    StateNotifierProvider<ExampleAudioController, ExampleAudioState>(
  (ref) => ExampleAudioController(
    player: ref.watch(audioPlayerProvider),
    repository: ref.watch(exampleAudioRepositoryProvider),
    textSequences: ref.watch(textSequenceRepositoryProvider),
  ),
);

class ExampleAudioController extends StateNotifier<ExampleAudioState> {
  final AudioPlayer _player;
  final ExampleAudioRepository _repository;
  final TextSequenceRepository _textSequences;

  ExampleAudioController({
    required AudioPlayer player,
    required ExampleAudioRepository repository,
    required TextSequenceRepository textSequences,
  })  : _player = player,
        _repository = repository,
        _textSequences = textSequences,
        super(const ExampleAudioState()) {
    _listenToPlayer();
  }

  void _listenToPlayer() {
    _player.stateStream.listen((playbackState) {
      if (playbackState == PlaybackState.completed ||
          playbackState == PlaybackState.error) {
        state = state.copyWith(
          isPlaying: false,
          currentSequenceId: null,
          currentVoiceId: null,
        );
      }
    });
  }

  /// Plays example audio for a sequence and voice.
  Future<void> play(String sequenceId, String voiceId) async {
    // Stop any current playback
    if (state.isPlaying) {
      await stop();
    }

    final sequence = await _textSequences.getById(sequenceId);
    if (sequence == null) {
      state = state.copyWith(error: 'Sequence not found');
      return;
    }

    try {
      final source = await _repository.resolveVoice(sequence, voiceId);
      if (source == null) {
        state = state.copyWith(error: 'Audio not available');
        return;
      }

      state = state.copyWith(
        isPlaying: true,
        currentSequenceId: sequenceId,
        currentVoiceId: voiceId,
        error: null,
      );

      await _player.load(source);
      await _player.play();
    } catch (e) {
      state = state.copyWith(
        isPlaying: false,
        error: 'Playback failed: $e',
      );
    }
  }

  /// Stops current playback.
  Future<void> stop() async {
    await _player.stop();
    state = state.copyWith(
      isPlaying: false,
      currentSequenceId: null,
      currentVoiceId: null,
    );
  }

  /// Pre-fetches audio for upcoming sequences.
  Future<void> prefetchSequence(String sequenceId) async {
    final sequence = await _textSequences.getById(sequenceId);
    if (sequence != null) {
      await _repository.prefetch(sequence);
    }
  }
}
```

---

## Integration Tests

### Repository Tests

```dart
void main() {
  group('ExampleAudioRepository', () {
    late ExampleAudioRepository repository;

    setUp(() {
      repository = ExampleAudioRepositoryImpl();
    });

    test('resolves asset URI', () async {
      final source = await repository.resolve(
        'assets://examples/female/ts_000001.opus',
      );

      expect(source, isA<AssetAudioSource>());
      expect(
        (source as AssetAudioSource).assetPath,
        'assets/examples/female/ts_000001.opus',
      );
    });

    test('resolves file URI', () async {
      // Create a temp file
      final tempDir = await Directory.systemTemp.createTemp();
      final file = File('${tempDir.path}/test.opus');
      await file.writeAsBytes([0, 1, 2, 3]);

      final source = await repository.resolve('file://${file.path}');

      expect(source, isA<FileAudioSource>());
      expect((source as FileAudioSource).filePath, file.path);

      await tempDir.delete(recursive: true);
    });

    test('returns null for non-existent file', () async {
      final source = await repository.resolve(
        'file:///nonexistent/path.opus',
      );
      expect(source, isNull);
    });

    test('resolves remote URI with caching', () async {
      // This would require mocking the HTTP client
      // or using a test server
    });

    test('isAvailableLocally returns true for assets', () async {
      final available = await repository.isAvailableLocally(
        'assets://examples/female/ts_000001.opus',
      );
      expect(available, isTrue);
    });
  });
}
```

### Controller Tests

```dart
void main() {
  group('ExampleAudioController', () {
    late MockAudioPlayer mockPlayer;
    late MockExampleAudioRepository mockRepository;
    late MockTextSequenceRepository mockTextSequences;
    late ExampleAudioController controller;

    setUp(() {
      mockPlayer = MockAudioPlayer();
      mockRepository = MockExampleAudioRepository();
      mockTextSequences = MockTextSequenceRepository();

      when(() => mockPlayer.stateStream).thenAnswer(
        (_) => Stream.empty(),
      );

      controller = ExampleAudioController(
        player: mockPlayer,
        repository: mockRepository,
        textSequences: mockTextSequences,
      );
    });

    test('play sets isPlaying state', () async {
      final sequence = TextSequence(
        id: 'ts_001',
        text: '你好',
        language: 'zh',
        exampleAudio: [
          ExampleVoice(id: 'f1', uri: 'assets://test.opus'),
        ],
      );

      when(() => mockTextSequences.getById('ts_001')).thenAnswer(
        (_) async => sequence,
      );
      when(() => mockRepository.resolveVoice(any(), 'f1')).thenAnswer(
        (_) async => const AssetAudioSource('assets/test.opus'),
      );
      when(() => mockPlayer.load(any())).thenAnswer((_) async {});
      when(() => mockPlayer.play()).thenAnswer((_) async {});

      await controller.play('ts_001', 'f1');

      expect(controller.state.isPlaying, isTrue);
      expect(controller.state.currentSequenceId, 'ts_001');
      expect(controller.state.currentVoiceId, 'f1');
    });

    test('stop clears playing state', () async {
      when(() => mockPlayer.stop()).thenAnswer((_) async {});

      await controller.stop();

      expect(controller.state.isPlaying, isFalse);
      expect(controller.state.currentSequenceId, isNull);
    });
  });
}
```

---

## Notes

### URI Schemes

| Scheme | Source | Example |
|--------|--------|---------|
| `assets://` | Bundled app assets | `assets://examples/female/ts_000001.opus` |
| `file://` | Local file system | `file:///data/cache/abc123.opus` |
| `https://` | Remote CDN | `https://cdn.example.com/examples/female/ts_000001.opus` |

### Audio Format

- **Format**: Opus in OGG container
- **Bitrate**: 12-20 kbps (sufficient for speech)
- **Benefits**: Small file size, high quality for speech

### Caching Strategy

- LRU cache with 200 file limit (~20-40 MB typical)
- Downloads cached to app support directory
- Cache cleaned on app start if over limit
- Files sorted by access time, oldest deleted first

### Prefetching

The `prefetch` method can be called when:
- User navigates to a sequence
- In the background for upcoming sequences
- On WiFi when dataset is loaded

This ensures smooth playback without loading delays.
